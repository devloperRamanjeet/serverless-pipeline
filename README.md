# ğŸ“˜ Developer Guide: AI Utils Lambda Pipeline

This guide explains how to **develop, test, and deploy AWS Lambda functions** using **VSCode, GitHub Actions, Terraform, and SAM CLI**.  
We use a **global `requirements.txt`** for dependencies to keep things simple and fast.

---

## ğŸ› ï¸ Step 1: Local Environment Setup

### Install tools
- Python 3.11 + `pip`
- VSCode (Python extension)
- AWS CLI â†’ `aws configure`
- AWS SAM CLI â†’ local Lambda testing
- Terraform â†’ infra provisioning
- Git

### Clone repo
```bash
git clone https://github.com/your-org/ai-utils-pipeline.git
cd ai-utils-pipeline
```

**Folder structure (initial skeleton):**
```bash
repo-root/
â”‚â”€â”€ .github/workflows/deploy.yml
â”‚â”€â”€ infra/
â”‚   â”œâ”€â”€ main.tf
â”‚   â””â”€â”€ sam-template.yaml
â”‚â”€â”€ common/utils.py
â”‚â”€â”€ functions/
â”‚â”€â”€ events/
â”‚â”€â”€ tests/
â”‚â”€â”€ requirements.txt   # global dependencies
â”‚â”€â”€ README.md
```

---

## ğŸ“ Step 2: Write the First Function

Create a new folder under `functions/`:

```bash
mkdir functions/ray_converter
```

Add `handler.py`:

```python
def lambda_handler(event, context):
    ray_data = event.get("ray", {})
    converted = {"standard": ray_data}
    return {
        "statusCode": 200,
        "body": converted
    }
```

Add a unit test in `functions/ray_converter/tests/test_handler.py`:

```python
from handler import lambda_handler

def test_lambda_handler():
    event = {"ray": {"x": 1, "y": 2}}
    result = lambda_handler(event, None)
    assert result["statusCode"] == 200
    assert "standard" in result["body"]
```

**Folder structure after adding function:**
```bash
repo-root/
â”‚â”€â”€ functions/
â”‚   â””â”€â”€ ray_converter/
â”‚       â”œâ”€â”€ handler.py
â”‚       â””â”€â”€ tests/test_handler.py
â”‚â”€â”€ events/
â”‚   â””â”€â”€ ray_event.json
â”‚â”€â”€ requirements.txt
```

---

## ğŸ§ª Step 3: Run Locally

### Option 1: Run Unit Tests (Fastest)

```bash
# Activate virtual environment
source .venv/bin/activate  # or .venv\Scripts\activate on Windows

# Run all tests
pytest functions/ray_converter/tests/ -v

# Run specific test
pytest functions/ray_converter/tests/test_handler.py::test_lambda_handler_success -v

# Run with coverage
pytest functions/ray_converter/tests/ --cov=functions/ray_converter --cov-report=html
```

### Option 2: Test Handler Manually with Python

```bash
# Test with sample event
python << 'EOF'
import json
import sys
sys.path.insert(0, "functions/ray_converter")
from handler import lambda_handler

# Load sample event
with open("events/ray_event.json") as f:
    event = json.load(f)

# Mock context
class MockContext:
    aws_request_id = "test-123"

# Run handler
result = lambda_handler(event, MockContext())
print(json.dumps(json.loads(result['body']), indent=2))
EOF
```

### Option 3: Use SAM CLI (Local Lambda Runtime)

```bash
# Install SAM CLI (if not already installed)
pip install aws-sam-cli

# Build and test locally
sam local start-api

# In another terminal, invoke the function
curl -X POST http://localhost:3000/ray \
  -H "Content-Type: application/json" \
  -d '{"ray": {"x": 10, "y": 20}}'
```

### Option 4: Create Custom Test Script

Create `test_locally.py` in the repo root:

```python
#!/usr/bin/env python
import json
import sys
sys.path.insert(0, "functions/ray_converter")
from handler import lambda_handler

def test_with_custom_data():
    test_cases = [
        {"name": "Basic", "ray": {"x": 10, "y": 20, "z": 30}},
        {"name": "Empty", "ray": {}},
        {"name": "Complex", "ray": {"coords": [1, 2, 3], "label": "test"}},
    ]
    
    class MockContext:
        aws_request_id = "local-test"
    
    for test in test_cases:
        event = test.copy()
        name = event.pop("name")
        result = lambda_handler(event, MockContext())
        print(f"âœ“ {name}: {result['statusCode']}")

if __name__ == "__main__":
    test_with_custom_data()
```

Run it:
```bash
python test_locally.py
```

---

## ğŸ“Š Sample Event in `events/ray_event.json`

```json
{ "ray": { "x": 10, "y": 20 } }
```

---

## ğŸ“‚ Step 8: Push Code to GitHub

```bash
git add functions/ray_converter
git commit -m "Add ray_converter Lambda function"
git push origin main
```

This triggers the GitHub Actions pipeline.

---

## â˜ï¸ Step 9: AWS Setup

- Create IAM role for Lambda execution.
- Create S3 bucket for deployment packages.
- Create API Gateway (if HTTP trigger needed).
- Configure Terraform backend (S3 + DynamoDB for state).

---

## âš™ï¸ Step 6: Configure Function Triggers

Instead of hardcoding triggers, use the **trigger configuration file** to enable/disable them easily.

### Trigger Configuration File: `config/triggers.yaml`

This file defines **how your Lambda function will be triggered**:

```yaml
functions:
  ray_converter:
    name: ray-converter
    runtime: python3.11
    
    # Enable/disable different trigger types
    api_gateway:
      enabled: true
      route: "POST /ray"
      
    sqs:
      enabled: false
      queue_name: "ray-converter-queue"
      
    s3:
      enabled: false
      bucket_name: "ray-converter-input"
      events: ["s3:ObjectCreated:*"]
      
    eventbridge:
      enabled: false
      schedule: "rate(1 hour)"
      
    # ... more triggers available
```

### Supported Triggers:

| Trigger Type | Use Case | Config Key |
|---|---|---|
| **API Gateway** | HTTP API endpoint (GET/POST) | `api_gateway` |
| **SQS** | Process async messages from queue | `sqs` |
| **S3** | Trigger on file upload | `s3` |
| **EventBridge** | Scheduled execution (cron/rate) | `eventbridge` |
| **DynamoDB** | Stream processing | `dynamodb` |
| **SNS** | Trigger on topic notification | `sns` |

### Enable/Disable Triggers:

1. **Enable API Gateway (HTTP endpoint):**
   ```yaml
   api_gateway:
     enabled: true
     route: "POST /ray"
   ```

2. **Enable SQS Queue:**
   ```yaml
   sqs:
     enabled: true
     queue_name: "ray-converter-queue"
     batch_size: 10
   ```

3. **Enable S3 Bucket Trigger:**
   ```yaml
   s3:
     enabled: true
     bucket_name: "ray-converter-input"
     events: ["s3:ObjectCreated:*"]
   ```

4. **Enable Scheduled Execution (EventBridge):**
   ```yaml
   eventbridge:
     enabled: true
     schedule: "rate(30 minutes)"  # or "cron(0 12 * * ? *)"
   ```

### View Enabled Triggers:

```bash
# Check which triggers are currently enabled
python common/trigger_config.py

# Output:
# âœ… Enabled Triggers:
# â€¢ API GATEWAY
#   Route: POST /ray
# â€¢ SQS
#   Queue: ray-converter-queue
#   Batch Size: 10
```

### Export Configuration:

```bash
# Export YAML config to JSON for use in scripts
python -c "from common.trigger_config import TriggerConfig; TriggerConfig().export_to_json()"
```

---

## âš™ï¸ Step 7: Terraform Infrastructure

Define Lambda + trigger in `infra/main.tf`:

```hcl
resource "aws_lambda_function" "ray_converter" {
  function_name = "ray_converter"
  handler       = "handler.lambda_handler"
  runtime       = "python3.11"
  role          = aws_iam_role.lambda_exec.arn
  filename      = "${path.module}/../build/ray_converter.zip"
}

resource "aws_apigatewayv2_route" "ray_converter_route" {
  api_id    = aws_apigatewayv2_api.http_api.id
  route_key = "POST /ray"
  target    = "integrations/${aws_apigatewayv2_integration.ray_converter_integration.id}"
}
```

Apply infra:

```bash
terraform init
terraform apply -auto-approve
```

---

## ğŸ”„ Step 10: GitHub Actions Workflow

`.github/workflows/deploy.yml`:

```yaml
name: Deploy Lambda Functions

on:
  push:
    branches: [ "main" ]

jobs:
  build-deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install global dependencies
        run: pip install -r requirements.txt -t python/

      - name: Package Lambda functions
        run: |
          mkdir build
          for dir in functions/*; do
            cd $dir
            zip -r ../../build/$(basename $dir).zip . ../../python
            cd -
          done

      - name: Deploy with Terraform
        run: |
          cd infra
          terraform init
          terraform apply -auto-approve
```

---

# ğŸ”„ Developer Workflow Recap
1. **Setup tools + clone repo** â†’ skeleton folders + global `requirements.txt`.  
2. **Write function** â†’ add folder + handler.  
3. **Test locally** â†’ sample events + SAM CLI + pytest.  
4. **Push to GitHub** â†’ pipeline triggers.  
5. **AWS setup** â†’ IAM, S3, API Gateway defined in `infra/`.  
6. **Terraform infra** â†’ reproducible infra + triggers.  
7. **YAML pipeline** â†’ automated build + deploy with global dependencies.

---
# ğŸ“Š CloudWatch Monitoring for Production Debugging

Your Lambda function includes **enterprise-grade CloudWatch monitoring** for production debugging:

## What's Monitored

- âœ… **Structured Logs** - JSON-formatted logs for easy parsing
- âœ… **Real-time Metrics** - Errors, warnings, success rate tracked
- âœ… **Auto Alarms** - Email alerts on errors, timeouts, throttles
- âœ… **Visual Dashboard** - Pre-built metrics dashboard
- âœ… **Log Insights** - Advanced querying and analysis

## Quick Start

### View Live Logs

```bash
# Stream logs in real-time
aws logs tail /aws/lambda/ray-converter --follow

# View last 100 lines
aws logs tail /aws/lambda/ray-converter --max-items 100
```

### Open Dashboard

```
AWS Console â†’ CloudWatch â†’ Dashboards â†’ ray-converter-metrics
```

### Enable Email Alerts

Edit `infra/terraform.tfvars`:
```terraform
enable_alarms = true
alert_email   = "your-email@example.com"  # Add your email
```

Then redeploy:
```bash
cd infra && terraform apply
```

### Query Logs in Logs Insights

Example query to find errors:
```
fields @timestamp, @message, request_id
| filter @message like /ERROR/
| stats count() as error_count by @message
```

## Full Documentation

See **[CLOUDWATCH_MONITORING_GUIDE.md](CLOUDWATCH_MONITORING_GUIDE.md)** for:
- Detailed monitoring setup
- All pre-built queries
- Production debugging workflows
- Troubleshooting guide
- Metrics explanations

---
# ğŸ“Š CODE FLOW DIAGRAM & EXECUTION PATH

## Local Development Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DEVELOPER'S LOCAL MACHINE                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1ï¸âƒ£  EDIT CODE
    â†“
    functions/ray_converter/handler.py
    â”œâ”€ Lambda function logic
    â”œâ”€ Input: event (Ray data)
    â””â”€ Output: converted standard format

2ï¸âƒ£  RUN LOCAL TESTS
    â†“
    pytest functions/ray_converter/tests/test_handler.py
    â”‚
    â”œâ”€ test_lambda_handler_success
    â”œâ”€ test_lambda_handler_empty_ray
    â”œâ”€ test_lambda_handler_missing_ray_key
    â””â”€ test_lambda_handler_with_none_context

3ï¸âƒ£  TEST WITH SAM CLI (Local Server)
    â†“
    sam local start-api --port 3000
    â”‚
    â””â”€ Starts local API server at http://localhost:3000/ray
       â”œâ”€ Receives POST request with JSON body
       â”œâ”€ Calls: functions/ray_converter/handler.py â†’ lambda_handler()
       â”œâ”€ Processes: event from request
       â””â”€ Returns: JSON response with statusCode 200

4ï¸âƒ£  TEST WITH CURL/POSTMAN
    â†“
    curl -X POST http://localhost:3000/ray \
      -H "Content-Type: application/json" \
      -d '{"ray": {"x": 10, "y": 20, "z": 30}}'
    â”‚
    â”œâ”€ Request hits: functions/ray_converter/handler.py
    â”œâ”€ Files accessed:
    â”‚   â”œâ”€ events/ray_event.json (sample data)
    â”‚   â””â”€ common/ (any utilities)
    â””â”€ Response body contains converted data
```

---

## Push to Git & GitHub Actions Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LOCAL GIT REPOSITORY                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

5ï¸âƒ£  COMMIT & PUSH CODE
    â†“
    $ git add functions/
    $ git commit -m "Update ray_converter handler"
    $ git push origin main
    â”‚
    â””â”€ Files pushed to GitHub:
       â”œâ”€ functions/ray_converter/handler.py
       â”œâ”€ functions/ray_converter/tests/test_handler.py
       â”œâ”€ requirements.txt
       â””â”€ infra/ (all Terraform files)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GITHUB ACTIONS PIPELINE TRIGGERED                  â”‚
â”‚           (.github/workflows/deploy.yml executed)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

6ï¸âƒ£  GITHUB ACTIONS: TEST JOB
    â†“
    Steps:
    â”œâ”€ Checkout: Clone repo
    â”œâ”€ Setup Python 3.11
    â”œâ”€ Install dependencies: pip install -r requirements.txt
    â”‚  â””â”€ Installs: pytest, boto3, aws-lambda-powertools
    â”‚
    â”œâ”€ Run unit tests:
    â”‚  â””â”€ pytest functions/ray_converter/tests/ -v
    â”‚     â”œâ”€ Runs all test_*.py files
    â”‚     â””â”€ If ANY test fails â†’ Pipeline STOPS âŒ
    â”‚
    â”œâ”€ Check code formatting:
    â”‚  â”œâ”€ black --check functions/
    â”‚  â””â”€ flake8 functions/
    â”‚
    â””â”€ If ALL tests pass â†’ Proceed to BUILD JOB âœ…

7ï¸âƒ£  GITHUB ACTIONS: BUILD & DEPLOY JOB
    â†“
    Prerequisites: All tests passed
    
    Steps:
    â”œâ”€ Checkout code
    â”œâ”€ Setup Python 3.11
    â”‚
    â”œâ”€ Install dependencies (with path):
    â”‚  â””â”€ pip install -r requirements.txt -t python/
    â”‚     â”œâ”€ Creates: python/ directory with all packages
    â”‚     â””â”€ This gets zipped with Lambda code
    â”‚
    â”œâ”€ Create build directory:
    â”‚  â””â”€ mkdir -p build/
    â”‚
    â”œâ”€ PACKAGE LAMBDA FUNCTION:
    â”‚  â”œâ”€ cd functions/ray_converter
    â”‚  â”œâ”€ zip -r ../../build/ray_converter.zip . ../../python
    â”‚  â””â”€ Output: build/ray_converter.zip
    â”‚     â”œâ”€ Contains: handler.py
    â”‚     â”œâ”€ Contains: all dependencies (from python/)
    â”‚     â””â”€ Size: Ready for AWS Lambda
    â”‚
    â”œâ”€ CONFIGURE AWS CREDENTIALS:
    â”‚  â””â”€ Uses GitHub Secrets:
    â”‚     â”œâ”€ AWS_ACCESS_KEY_ID
    â”‚     â””â”€ AWS_SECRET_ACCESS_KEY
    â”‚
    â”œâ”€ DEPLOY WITH TERRAFORM:
    â”‚  â”œâ”€ cd infra
    â”‚  â”œâ”€ terraform init
    â”‚  â”‚  â””â”€ Initializes Terraform workspace
    â”‚  â”‚
    â”‚  â”œâ”€ terraform plan -out=tfplan
    â”‚  â”‚  â””â”€ Reviews what will be created
    â”‚  â”‚
    â”‚  â””â”€ terraform apply tfplan
    â”‚     â”œâ”€ Creates AWS resources:
    â”‚     â”‚  â”œâ”€ AWS Lambda Function
    â”‚     â”‚  â”‚  â””â”€ Uses: build/ray_converter.zip
    â”‚     â”‚  â”œâ”€ AWS API Gateway
    â”‚     â”‚  â”œâ”€ AWS IAM Role
    â”‚     â”‚  â”œâ”€ AWS CloudWatch Logs
    â”‚     â”‚  â””â”€ AWS Lambda Permissions
    â”‚     â”‚
    â”‚     â””â”€ Reads config from:
    â”‚        â”œâ”€ infra/main.tf
    â”‚        â”œâ”€ infra/triggers.tf
    â”‚        â”œâ”€ infra/triggers_conditional.tf
    â”‚        â”œâ”€ infra/variables.tf
    â”‚        â””â”€ infra/terraform.tfvars
    â”‚
    â””â”€ OUTPUT RESULTS:
       â””â”€ terraform output
          â”œâ”€ Lambda ARN
          â”œâ”€ API Gateway Endpoint (YOUR API URL)
          â””â”€ Log group name
```

---

## File Execution Flow During Different Stages

### Stage 1: Local Development
```
Your Code Change
    â†“
handler.py (EDITED)
    â”œâ”€ You make changes here
    â””â”€ Add business logic
    
Run Local Test
    â†“
tests/test_handler.py (EXECUTED)
    â”œâ”€ Imports: from handler import lambda_handler
    â”œâ”€ Calls: lambda_handler(event, context)
    â””â”€ Verifies: Results match expected output
    
Test with SAM
    â†“
template.yaml (READ by SAM)
    â”œâ”€ Defines: CodeUri: functions/ray_converter/
    â””â”€ SAM starts Flask server at http://localhost:3000

cURL/Postman Request
    â†“
handler.py (CALLED)
    â”œâ”€ Entry point: lambda_handler(event, context)
    â”œâ”€ Reads: event["ray"] from request body
    â”œâ”€ Processes: Ray data
    â””â”€ Returns: Converted format
    
events/ray_event.json (REFERENCE)
    â””â”€ Shows example of what to send
```

### Stage 2: Push to GitHub
```
$ git push origin main
    â†“
GitHub receives push
    â†“
.github/workflows/deploy.yml (TRIGGERED)
    â”œâ”€ Reads: Files in push
    â”œâ”€ Checks: requirements.txt
    â”œâ”€ Runs: tests from functions/ray_converter/tests/
    â””â”€ If OK: Proceeds to build
```

### Stage 3: Build & Package
```
.github/workflows/deploy.yml (CONTINUES)
    â†“
requirements.txt (READ)
    â”œâ”€ Installs all packages locally
    â””â”€ Bundles into: python/ directory
    
handler.py (PACKAGED)
    â”œâ”€ Zipped with all dependencies
    â””â”€ Output: build/ray_converter.zip
    
Terraform files (PREPARED)
    â”œâ”€ infra/main.tf
    â”œâ”€ infra/triggers.tf
    â”œâ”€ infra/triggers_conditional.tf
    â”œâ”€ infra/variables.tf
    â””â”€ infra/terraform.tfvars
```

### Stage 4: Deploy to AWS
```
terraform init (SETUP)
    â”œâ”€ Downloads AWS provider plugin
    â”œâ”€ Creates: .terraform/ directory
    â””â”€ Sets up: State management
    
terraform plan (REVIEW)
    â”œâ”€ Reads: infra/main.tf
    â”œâ”€ Checks: Current AWS state
    â””â”€ Shows: What will change
    
terraform apply (DEPLOY)
    â”œâ”€ Reads: build/ray_converter.zip
    â”œâ”€ Creates: AWS Lambda Function
    â”‚  â”œâ”€ Function name: ray-converter
    â”‚  â”œâ”€ Handler: handler.lambda_handler
    â”‚  â”œâ”€ Code: build/ray_converter.zip
    â”‚  â””â”€ Runtime: python3.11
    â”‚
    â”œâ”€ Creates: API Gateway
    â”‚  â”œâ”€ Route: POST /ray
    â”‚  â”œâ”€ Integration: Lambda function
    â”‚  â””â”€ CORS: Enabled
    â”‚
    â”œâ”€ Creates: IAM Role
    â”‚  â””â”€ Permissions: Lambda execution
    â”‚
    â”œâ”€ Creates: CloudWatch Log Group
    â”‚  â””â”€ Name: /aws/lambda/ray-converter
    â”‚
    â””â”€ Outputs:
       â”œâ”€ api_gateway_endpoint
       â”œâ”€ lambda_function_arn
       â””â”€ lambda_function_name
```

### Stage 5: Live API Usage
```
After Deployment
    â†“
Your API is LIVE at:
    https://xxxxx.execute-api.us-east-1.amazonaws.com/dev/ray
    
POST Request
    â†“
API Gateway receives
    â”œâ”€ Route: POST /ray
    â”œâ”€ Validates: CORS
    â””â”€ Forwards to: Lambda
    
AWS Lambda Execution
    â”œâ”€ Loads: build/ray_converter.zip
    â”œâ”€ Executes: handler.lambda_handler()
    â”œâ”€ Reads: event from request body
    â”œâ”€ Processes: Ray data conversion
    â”œâ”€ Logs to: CloudWatch (/aws/lambda/ray-converter)
    â””â”€ Returns: JSON response
    
Response sent back
    â”œâ”€ Status: 200 (on success)
    â”œâ”€ Body: Converted ray data
    â””â”€ User receives: Result
```

---

## Which Files Get Hit at Each Stage

### ğŸ”´ Local Testing (Your Machine)
| Stage | Primary Files | Secondary Files |
|-------|------|---------|
| Edit Code | `functions/ray_converter/handler.py` | `common/utils.py` |
| Run Tests | `functions/ray_converter/tests/test_handler.py` | `requirements.txt` |
| SAM Local | `template.yaml` | `functions/ray_converter/handler.py` |
| Manual Test | `events/ray_event.json` | `handler.py` |

### ğŸ”µ GitHub Actions (Automated)
| Stage | Primary Files | Secondary Files |
|-------|------|---------|
| Trigger | `.github/workflows/deploy.yml` | All changed files |
| Test | `requirements.txt` | `functions/ray_converter/tests/` |
| Build | `functions/ray_converter/handler.py` | `requirements.txt` |
| Package | `build/ray_converter.zip` (output) | All Python files |
| Deploy | `infra/main.tf`, `infra/triggers.tf` | `infra/variables.tf`, `terraform.tfvars` |

### ğŸŸ¢ AWS (After Deployment)
| Stage | Files Executed | Where |
|-------|------|---------|
| API Call | `build/ray_converter.zip` | AWS Lambda |
| Handler | `handler.lambda_handler()` | Lambda runtime |
| Logging | Outputs to | `/aws/lambda/ray-converter` CloudWatch |

---

## Next Steps After Each Stage

### After Local Testing âœ…
```
If ALL tests pass:
    â†“
$ git add functions/ infra/ requirements.txt
$ git commit -m "Ray converter Lambda function ready"
$ git push origin main
```

### After Push to GitHub ğŸ”„
```
GitHub Actions automatically:
    â”œâ”€ Runs tests
    â”œâ”€ Builds package
    â”œâ”€ Deploys to AWS
    â””â”€ Sends status back
```

### After Deployment âœ…
```
Lambda is LIVE!
    â”œâ”€ API Endpoint: terraform output api_gateway_endpoint
    â”œâ”€ Test: curl -X POST <endpoint> ...
    â”œâ”€ Monitor: AWS Console â†’ Lambda
    â””â”€ Logs: CloudWatch â†’ /aws/lambda/ray-converter
```

### To Update Code ğŸ”„
```
1. Edit: functions/ray_converter/handler.py
2. Test: pytest functions/ray_converter/tests/
3. Push: git push origin main
4. GitHub Actions auto-deploys the changes
5. Your API is updated (no manual steps needed!)
```

---

## Configuration Flow

### Trigger Configuration
```
config/triggers.yaml (YOU EDIT THIS)
    â†“
common/trigger_config.py (READS & PARSES)
    â”œâ”€ Validates YAML
    â”œâ”€ Checks enabled triggers
    â””â”€ Exports to JSON
    
infra/triggers_conditional.tf (USES THIS)
    â”œâ”€ Reads trigger settings
    â”œâ”€ Creates enabled resources
    â””â”€ Skips disabled ones
```

### How to Enable More Triggers
```
1. Edit config/triggers.yaml
   sqs:
     enabled: true    # Change from false to true
     
2. Run: python common/trigger_config.py
   â””â”€ Validates your changes
   
3. Deploy: cd infra && terraform apply
   â””â”€ Creates SQS queue + Lambda mapping
   
4. Result: Lambda now triggers from SQS!
```  
